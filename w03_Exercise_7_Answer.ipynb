{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w03: Exercise 7 - Answer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denpetrov/convolutional_neural_networks_tensorflow/blob/master/w03_Exercise_7_Answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a177e234-a3e9-49fa-85e0-155505aa76a4"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-06 19:06:24--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   131MB/s    in 0.6s    \n",
            "\n",
            "2019-07-06 19:06:25 (131 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 7, 7, 192)    576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 7, 7, 192)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 7, 7, 192)    258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 3, 3, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 3, 3, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 3, 3, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 3, 3, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 3, 3, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 3, 3, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 3, 3, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 3, 3, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 3, 3, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 3, 3, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 3, 3, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "8fe368e4-7ecd-4c2e-af67-b7d299b2f660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25db289e-b04a-4dc7-e03d-67d06fe1805a"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "b4f29bf4-81b9-4d6a-907d-7b5908ee906c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-06 19:06:36--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   228MB/s    in 0.6s    \n",
            "\n",
            "2019-07-06 19:06:37 (228 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-07-06 19:06:38--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-07-06 19:06:39 (178 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "804901e7-8c61-40b6-cdba-3f28d1068e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "2688a08a-276b-492b-c424-5a797b97b7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "78b4affd-1761-42ec-f4a9-248fa09b98d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 31s - loss: 0.1952 - acc: 0.9174 - val_loss: 0.0296 - val_acc: 0.9889\n",
            "Epoch 2/100\n",
            "100/100 - 25s - loss: 0.0723 - acc: 0.9721 - val_loss: 4.3939e-04 - val_acc: 1.0000\n",
            "Epoch 3/100\n",
            "100/100 - 24s - loss: 0.0556 - acc: 0.9813 - val_loss: 0.0262 - val_acc: 0.9879\n",
            "Epoch 4/100\n",
            "100/100 - 24s - loss: 0.0462 - acc: 0.9833 - val_loss: 0.0025 - val_acc: 1.0000\n",
            "Epoch 5/100\n",
            "100/100 - 23s - loss: 0.0270 - acc: 0.9904 - val_loss: 0.0370 - val_acc: 0.9919\n",
            "Epoch 6/100\n",
            "100/100 - 23s - loss: 0.0288 - acc: 0.9914 - val_loss: 0.0052 - val_acc: 0.9970\n",
            "Epoch 7/100\n",
            "100/100 - 23s - loss: 0.0233 - acc: 0.9919 - val_loss: 0.0054 - val_acc: 0.9960\n",
            "Epoch 8/100\n",
            "100/100 - 23s - loss: 0.0372 - acc: 0.9863 - val_loss: 0.0900 - val_acc: 0.9879\n",
            "Epoch 9/100\n",
            "100/100 - 23s - loss: 0.0265 - acc: 0.9914 - val_loss: 0.0524 - val_acc: 0.9960\n",
            "Epoch 10/100\n",
            "100/100 - 23s - loss: 0.0209 - acc: 0.9934 - val_loss: 0.0678 - val_acc: 0.9919\n",
            "Epoch 11/100\n",
            "100/100 - 23s - loss: 0.0348 - acc: 0.9909 - val_loss: 0.0712 - val_acc: 0.9960\n",
            "Epoch 12/100\n",
            "100/100 - 23s - loss: 0.0191 - acc: 0.9924 - val_loss: 0.0626 - val_acc: 0.9960\n",
            "Epoch 13/100\n",
            "100/100 - 23s - loss: 0.0152 - acc: 0.9954 - val_loss: 0.1038 - val_acc: 0.9838\n",
            "Epoch 14/100\n",
            "100/100 - 22s - loss: 0.0290 - acc: 0.9909 - val_loss: 0.1359 - val_acc: 0.9737\n",
            "Epoch 15/100\n",
            "100/100 - 24s - loss: 0.0334 - acc: 0.9889 - val_loss: 0.0509 - val_acc: 0.9919\n",
            "Epoch 16/100\n",
            "100/100 - 24s - loss: 0.0143 - acc: 0.9949 - val_loss: 0.2125 - val_acc: 0.9666\n",
            "Epoch 17/100\n",
            "100/100 - 23s - loss: 0.0375 - acc: 0.9919 - val_loss: 0.3076 - val_acc: 0.9565\n",
            "Epoch 18/100\n",
            "100/100 - 23s - loss: 0.0130 - acc: 0.9964 - val_loss: 0.2465 - val_acc: 0.9686\n",
            "Epoch 19/100\n",
            "100/100 - 23s - loss: 0.0249 - acc: 0.9934 - val_loss: 0.1963 - val_acc: 0.9838\n",
            "Epoch 20/100\n",
            "100/100 - 23s - loss: 0.0266 - acc: 0.9944 - val_loss: 0.1762 - val_acc: 0.9777\n",
            "Epoch 21/100\n",
            "100/100 - 23s - loss: 0.0115 - acc: 0.9959 - val_loss: 0.0894 - val_acc: 0.9879\n",
            "Epoch 22/100\n",
            "100/100 - 23s - loss: 0.0212 - acc: 0.9954 - val_loss: 0.5747 - val_acc: 0.9453\n",
            "Epoch 23/100\n",
            "100/100 - 23s - loss: 0.0170 - acc: 0.9960 - val_loss: 0.0607 - val_acc: 0.9960\n",
            "Epoch 24/100\n",
            "100/100 - 23s - loss: 0.0176 - acc: 0.9959 - val_loss: 0.0627 - val_acc: 0.9879\n",
            "Epoch 25/100\n",
            "100/100 - 23s - loss: 0.0129 - acc: 0.9969 - val_loss: 0.1078 - val_acc: 0.9879\n",
            "Epoch 26/100\n",
            "100/100 - 23s - loss: 0.0120 - acc: 0.9950 - val_loss: 0.1238 - val_acc: 0.9919\n",
            "Epoch 27/100\n",
            "100/100 - 22s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.1049 - val_acc: 0.9919\n",
            "Epoch 28/100\n",
            "100/100 - 24s - loss: 0.0291 - acc: 0.9909 - val_loss: 0.2795 - val_acc: 0.9686\n",
            "Epoch 29/100\n",
            "100/100 - 24s - loss: 0.0206 - acc: 0.9944 - val_loss: 0.1516 - val_acc: 0.9818\n",
            "Epoch 30/100\n",
            "100/100 - 23s - loss: 0.0099 - acc: 0.9970 - val_loss: 0.3020 - val_acc: 0.9666\n",
            "Epoch 31/100\n",
            "100/100 - 23s - loss: 0.0182 - acc: 0.9949 - val_loss: 0.4324 - val_acc: 0.9565\n",
            "Epoch 32/100\n",
            "100/100 - 23s - loss: 0.0147 - acc: 0.9950 - val_loss: 0.2171 - val_acc: 0.9777\n",
            "Epoch 33/100\n",
            "100/100 - 23s - loss: 0.0150 - acc: 0.9964 - val_loss: 0.2572 - val_acc: 0.9737\n",
            "Epoch 34/100\n",
            "100/100 - 23s - loss: 0.0105 - acc: 0.9980 - val_loss: 0.1874 - val_acc: 0.9757\n",
            "Epoch 35/100\n",
            "100/100 - 23s - loss: 0.0215 - acc: 0.9949 - val_loss: 0.4582 - val_acc: 0.9595\n",
            "Epoch 36/100\n",
            "100/100 - 23s - loss: 0.0205 - acc: 0.9935 - val_loss: 0.1046 - val_acc: 0.9939\n",
            "Epoch 37/100\n",
            "100/100 - 23s - loss: 0.0096 - acc: 0.9970 - val_loss: 0.2301 - val_acc: 0.9737\n",
            "Epoch 38/100\n",
            "100/100 - 23s - loss: 0.0085 - acc: 0.9980 - val_loss: 0.2197 - val_acc: 0.9757\n",
            "Epoch 39/100\n",
            "100/100 - 23s - loss: 0.0060 - acc: 0.9985 - val_loss: 0.1446 - val_acc: 0.9919\n",
            "Epoch 40/100\n",
            "100/100 - 22s - loss: 0.0032 - acc: 0.9985 - val_loss: 0.4102 - val_acc: 0.9595\n",
            "Epoch 41/100\n",
            "100/100 - 24s - loss: 0.0148 - acc: 0.9975 - val_loss: 0.2906 - val_acc: 0.9626\n",
            "Epoch 42/100\n",
            "100/100 - 24s - loss: 0.0281 - acc: 0.9939 - val_loss: 0.3656 - val_acc: 0.9676\n",
            "Epoch 43/100\n",
            "100/100 - 23s - loss: 0.0204 - acc: 0.9965 - val_loss: 0.3002 - val_acc: 0.9696\n",
            "Epoch 44/100\n",
            "100/100 - 23s - loss: 0.0112 - acc: 0.9964 - val_loss: 0.9565 - val_acc: 0.9464\n",
            "Epoch 45/100\n",
            "100/100 - 23s - loss: 0.0067 - acc: 0.9975 - val_loss: 0.3832 - val_acc: 0.9595\n",
            "Epoch 46/100\n",
            "100/100 - 23s - loss: 0.0130 - acc: 0.9959 - val_loss: 0.4590 - val_acc: 0.9615\n",
            "Epoch 47/100\n",
            "100/100 - 23s - loss: 0.0137 - acc: 0.9980 - val_loss: 0.6589 - val_acc: 0.9534\n",
            "Epoch 48/100\n",
            "100/100 - 23s - loss: 0.0042 - acc: 0.9980 - val_loss: 0.1442 - val_acc: 0.9889\n",
            "Epoch 49/100\n",
            "100/100 - 23s - loss: 0.0127 - acc: 0.9970 - val_loss: 0.3024 - val_acc: 0.9696\n",
            "Epoch 50/100\n",
            "100/100 - 23s - loss: 0.0101 - acc: 0.9975 - val_loss: 0.1783 - val_acc: 0.9838\n",
            "Epoch 51/100\n",
            "100/100 - 23s - loss: 0.0071 - acc: 0.9975 - val_loss: 0.5481 - val_acc: 0.9565\n",
            "Epoch 52/100\n",
            "100/100 - 23s - loss: 0.0196 - acc: 0.9975 - val_loss: 0.3888 - val_acc: 0.9656\n",
            "Epoch 53/100\n",
            "100/100 - 22s - loss: 0.0120 - acc: 0.9970 - val_loss: 0.2990 - val_acc: 0.9737\n",
            "Epoch 54/100\n",
            "100/100 - 24s - loss: 0.0050 - acc: 0.9990 - val_loss: 0.2758 - val_acc: 0.9696\n",
            "Epoch 55/100\n",
            "100/100 - 24s - loss: 0.0134 - acc: 0.9975 - val_loss: 0.1164 - val_acc: 0.9929\n",
            "Epoch 56/100\n",
            "100/100 - 23s - loss: 0.0053 - acc: 0.9980 - val_loss: 0.1121 - val_acc: 0.9919\n",
            "Epoch 57/100\n",
            "100/100 - 23s - loss: 0.0077 - acc: 0.9975 - val_loss: 0.4942 - val_acc: 0.9605\n",
            "Epoch 58/100\n",
            "100/100 - 23s - loss: 0.0245 - acc: 0.9960 - val_loss: 0.2457 - val_acc: 0.9757\n",
            "Epoch 59/100\n",
            "100/100 - 23s - loss: 0.0152 - acc: 0.9954 - val_loss: 0.2424 - val_acc: 0.9767\n",
            "Epoch 60/100\n",
            "100/100 - 23s - loss: 0.0032 - acc: 0.9985 - val_loss: 0.0704 - val_acc: 0.9960\n",
            "Epoch 61/100\n",
            "100/100 - 23s - loss: 0.0021 - acc: 0.9990 - val_loss: 0.2330 - val_acc: 0.9798\n",
            "Epoch 62/100\n",
            "100/100 - 23s - loss: 0.0040 - acc: 0.9990 - val_loss: 0.1464 - val_acc: 0.9879\n",
            "Epoch 63/100\n",
            "100/100 - 23s - loss: 0.0141 - acc: 0.9970 - val_loss: 0.2219 - val_acc: 0.9838\n",
            "Epoch 64/100\n",
            "100/100 - 23s - loss: 0.0175 - acc: 0.9975 - val_loss: 0.1610 - val_acc: 0.9848\n",
            "Epoch 65/100\n",
            "100/100 - 23s - loss: 0.0114 - acc: 0.9965 - val_loss: 0.1396 - val_acc: 0.9889\n",
            "Epoch 66/100\n",
            "100/100 - 22s - loss: 0.0211 - acc: 0.9970 - val_loss: 0.1659 - val_acc: 0.9889\n",
            "Epoch 67/100\n",
            "100/100 - 24s - loss: 0.0141 - acc: 0.9965 - val_loss: 0.1673 - val_acc: 0.9848\n",
            "Epoch 68/100\n",
            "100/100 - 24s - loss: 0.0379 - acc: 0.9960 - val_loss: 0.2650 - val_acc: 0.9787\n",
            "Epoch 69/100\n",
            "100/100 - 23s - loss: 0.0018 - acc: 0.9990 - val_loss: 0.2176 - val_acc: 0.9757\n",
            "Epoch 70/100\n",
            "100/100 - 23s - loss: 0.0016 - acc: 0.9990 - val_loss: 0.1267 - val_acc: 0.9919\n",
            "Epoch 71/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 23s - loss: 7.1399e-04 - acc: 0.9995 - val_loss: 0.1588 - val_acc: 0.9899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "e4989430-985a-425e-ce3c-87f8e8004ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}