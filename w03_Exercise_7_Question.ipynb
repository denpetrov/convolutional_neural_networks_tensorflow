{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w03: Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denpetrov/convolutional_neural_networks_tensorflow/blob/master/w03_Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6cbfef72-c201-4628-9be9-5aef2d1232a2"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (300, 300, 3),  # Your Code Here\n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  # Your Code Here\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-06 14:27:31--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.128, 2404:6800:4003:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  52.3MB/s    in 1.6s    \n",
            "\n",
            "2019-07-06 14:27:33 (52.3 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0706 14:27:35.277102 140013361297280 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7a32afa-384c-4aa6-a731-5fb533b2201b"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed10')  # Your Code Here\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output  # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 8, 8, 2048))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc') > 0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f63ff86e-b11d-4701-cd27-0fffc9e49f1e"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)  # Your Code Here\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)  # Your Code Here\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)  # Your Code Here\n",
        "\n",
        "model = Model( pre_trained_model.input, x)  # Your Code Here\n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy',  # Your Code Here, \n",
        "              metrics = ['acc'])  # Your Code Here\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0706 14:37:33.780069 140013361297280 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 131072)       0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         134218752   flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 156,022,561\n",
            "Trainable params: 134,219,777\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "23eaa705-9a0b-4296-d51b-0c9b43affaa1"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-06 14:38:23--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.128, 2404:6800:4003:c02::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  92.2MB/s    in 1.5s    \n",
            "\n",
            "2019-07-06 14:38:25 (92.2 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-07-06 14:38:26--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.128, 2404:6800:4003:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-07-06 14:38:27 (121 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8a4c71b0-db1c-4fc3-c505-dab26ad3080b"
      },
      "source": [
        "train_dir = os.path.join('/tmp', 'training')\n",
        "validation_dir = os.path.join('/tmp', 'validation')\n",
        "\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses')  # Your Code Here\n",
        "train_humans_dir = os.path.join(train_dir, 'humans')  # Your Code Here\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses')  # Your Code Here\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')  # Your Code Here\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)  # Your Code Here\n",
        "train_humans_fnames = os.listdir(train_humans_dir)  # Your Code Here\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)  # Your Code Here\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)  # Your Code Here\n",
        "\n",
        "print(len(train_horses_fnames))  # Your Code Here\n",
        "print(len(train_humans_fnames))  # Your Code Here\n",
        "print(len(validation_horses_fnames))  # Your Code Here\n",
        "print(len(validation_humans_fnames))  # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3dc2b7ac-d6a0-4c47-bacd-0458ad70ffc6"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)  # Your Code Here\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)  # Your Code Here\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (300, 300))  # Your Code Here\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (300, 300))  # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab0235f8-48ba-4b75-e22a-e952602ec08d"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()  # Your Code Here\n",
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data = validation_generator,\n",
        "                              steps_per_epoch = 100,\n",
        "                              epochs = 100,\n",
        "                              validation_steps = 50,\n",
        "                              verbose = 2,\n",
        "                              callbacks=[callbacks])  # Your Code Here"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 73s - loss: 1.2596 - acc: 0.9169 - val_loss: 0.3769 - val_acc: 0.9757\n",
            "Epoch 2/100\n",
            "100/100 - 66s - loss: 0.7109 - acc: 0.9595 - val_loss: 0.6881 - val_acc: 0.9504\n",
            "Epoch 3/100\n",
            "100/100 - 65s - loss: 0.1165 - acc: 0.9859 - val_loss: 0.1107 - val_acc: 0.9879\n",
            "Epoch 4/100\n",
            "100/100 - 64s - loss: 0.2206 - acc: 0.9811 - val_loss: 0.4155 - val_acc: 0.9777\n",
            "Epoch 5/100\n",
            "100/100 - 64s - loss: 0.2295 - acc: 0.9823 - val_loss: 0.1641 - val_acc: 0.9889\n",
            "Epoch 6/100\n",
            "100/100 - 64s - loss: 0.3642 - acc: 0.9814 - val_loss: 1.8471 - val_acc: 0.9231\n",
            "Epoch 7/100\n",
            "100/100 - 62s - loss: 0.1771 - acc: 0.9883 - val_loss: 0.1517 - val_acc: 0.9929\n",
            "Epoch 8/100\n",
            "100/100 - 64s - loss: 0.2176 - acc: 0.9869 - val_loss: 0.0607 - val_acc: 0.9929\n",
            "Epoch 9/100\n",
            "100/100 - 64s - loss: 0.2256 - acc: 0.9828 - val_loss: 0.0952 - val_acc: 0.9960\n",
            "Epoch 10/100\n",
            "100/100 - 64s - loss: 0.0618 - acc: 0.9949 - val_loss: 0.4310 - val_acc: 0.9818\n",
            "Epoch 11/100\n",
            "100/100 - 63s - loss: 0.0683 - acc: 0.9873 - val_loss: 0.2383 - val_acc: 0.9879\n",
            "Epoch 12/100\n",
            "100/100 - 62s - loss: 0.1075 - acc: 0.9944 - val_loss: 0.2422 - val_acc: 0.9899\n",
            "Epoch 13/100\n",
            "100/100 - 63s - loss: 0.1366 - acc: 0.9925 - val_loss: 0.2209 - val_acc: 0.9909\n",
            "Epoch 14/100\n",
            "100/100 - 61s - loss: 0.3203 - acc: 0.9823 - val_loss: 0.1139 - val_acc: 0.9960\n",
            "Epoch 15/100\n",
            "100/100 - 65s - loss: 0.1145 - acc: 0.9934 - val_loss: 1.9513 - val_acc: 0.9332\n",
            "Epoch 16/100\n",
            "100/100 - 65s - loss: 0.1189 - acc: 0.9904 - val_loss: 1.0411 - val_acc: 0.9474\n",
            "Epoch 17/100\n",
            "100/100 - 63s - loss: 0.1339 - acc: 0.9904 - val_loss: 0.4356 - val_acc: 0.9818\n",
            "Epoch 18/100\n",
            "100/100 - 63s - loss: 0.1771 - acc: 0.9904 - val_loss: 0.2233 - val_acc: 0.9868\n",
            "Epoch 19/100\n",
            "100/100 - 63s - loss: 0.1077 - acc: 0.9925 - val_loss: 0.2592 - val_acc: 0.9828\n",
            "Epoch 20/100\n",
            "100/100 - 63s - loss: 0.0570 - acc: 0.9954 - val_loss: 0.5803 - val_acc: 0.9757\n",
            "Epoch 21/100\n",
            "100/100 - 63s - loss: 0.0974 - acc: 0.9918 - val_loss: 0.3263 - val_acc: 0.9787\n",
            "Epoch 22/100\n",
            "100/100 - 63s - loss: 0.0415 - acc: 0.9950 - val_loss: 0.4851 - val_acc: 0.9767\n",
            "Epoch 23/100\n",
            "100/100 - 62s - loss: 0.2553 - acc: 0.9878 - val_loss: 0.0949 - val_acc: 0.9960\n",
            "Epoch 24/100\n",
            "100/100 - 63s - loss: 0.1651 - acc: 0.9904 - val_loss: 0.6065 - val_acc: 0.9727\n",
            "Epoch 25/100\n",
            "100/100 - 63s - loss: 0.1373 - acc: 0.9929 - val_loss: 0.7449 - val_acc: 0.9696\n",
            "Epoch 26/100\n",
            "100/100 - 63s - loss: 0.1673 - acc: 0.9919 - val_loss: 2.4761 - val_acc: 0.9008\n",
            "Epoch 27/100\n",
            "100/100 - 61s - loss: 0.0345 - acc: 0.9985 - val_loss: 0.4200 - val_acc: 0.9777\n",
            "Epoch 28/100\n",
            "100/100 - 65s - loss: 0.0538 - acc: 0.9954 - val_loss: 1.3411 - val_acc: 0.9464\n",
            "Epoch 29/100\n",
            "100/100 - 65s - loss: 0.0589 - acc: 0.9959 - val_loss: 1.2302 - val_acc: 0.9534\n",
            "Epoch 30/100\n",
            "100/100 - 64s - loss: 0.0966 - acc: 0.9934 - val_loss: 0.2700 - val_acc: 0.9889\n",
            "Epoch 31/100\n",
            "100/100 - 62s - loss: 0.0550 - acc: 0.9949 - val_loss: 0.5465 - val_acc: 0.9757\n",
            "Epoch 32/100\n",
            "100/100 - 62s - loss: 0.0932 - acc: 0.9930 - val_loss: 0.6684 - val_acc: 0.9615\n",
            "Epoch 33/100\n",
            "100/100 - 64s - loss: 0.0554 - acc: 0.9965 - val_loss: 0.3823 - val_acc: 0.9828\n",
            "Epoch 34/100\n",
            "100/100 - 64s - loss: 0.1062 - acc: 0.9939 - val_loss: 1.3022 - val_acc: 0.9565\n",
            "Epoch 35/100\n",
            "100/100 - 63s - loss: 0.0631 - acc: 0.9939 - val_loss: 1.2144 - val_acc: 0.9545\n",
            "Epoch 36/100\n",
            "100/100 - 64s - loss: 0.0443 - acc: 0.9970 - val_loss: 1.5893 - val_acc: 0.9383\n",
            "Epoch 37/100\n",
            "100/100 - 63s - loss: 0.0293 - acc: 0.9965 - val_loss: 2.3528 - val_acc: 0.9251\n",
            "Epoch 38/100\n",
            "100/100 - 63s - loss: 0.0567 - acc: 0.9959 - val_loss: 1.4759 - val_acc: 0.9433\n",
            "Epoch 39/100\n",
            "100/100 - 63s - loss: 0.1176 - acc: 0.9914 - val_loss: 0.6709 - val_acc: 0.9747\n",
            "Epoch 40/100\n",
            "100/100 - 61s - loss: 0.0788 - acc: 0.9975 - val_loss: 0.5981 - val_acc: 0.9747\n",
            "Epoch 41/100\n",
            "100/100 - 65s - loss: 0.1242 - acc: 0.9929 - val_loss: 1.1575 - val_acc: 0.9615\n",
            "Epoch 42/100\n",
            "100/100 - 65s - loss: 0.0552 - acc: 0.9944 - val_loss: 0.7157 - val_acc: 0.9696\n",
            "Epoch 43/100\n",
            "100/100 - 63s - loss: 0.0533 - acc: 0.9959 - val_loss: 0.5057 - val_acc: 0.9767\n",
            "Epoch 44/100\n",
            "100/100 - 63s - loss: 0.0503 - acc: 0.9970 - val_loss: 1.7012 - val_acc: 0.9423\n",
            "Epoch 45/100\n",
            "100/100 - 63s - loss: 0.0096 - acc: 0.9990 - val_loss: 0.4877 - val_acc: 0.9777\n",
            "Epoch 46/100\n",
            "100/100 - 63s - loss: 0.0342 - acc: 0.9960 - val_loss: 0.8291 - val_acc: 0.9747\n",
            "Epoch 47/100\n",
            "100/100 - 63s - loss: 0.0417 - acc: 0.9965 - val_loss: 0.2869 - val_acc: 0.9787\n",
            "Epoch 48/100\n",
            "100/100 - 63s - loss: 0.1118 - acc: 0.9949 - val_loss: 0.8978 - val_acc: 0.9686\n",
            "Epoch 49/100\n",
            "100/100 - 64s - loss: 0.0545 - acc: 0.9959 - val_loss: 0.2122 - val_acc: 0.9858\n",
            "Epoch 50/100\n",
            "100/100 - 62s - loss: 0.0289 - acc: 0.9975 - val_loss: 0.7517 - val_acc: 0.9696\n",
            "Epoch 51/100\n",
            "100/100 - 63s - loss: 0.0294 - acc: 0.9965 - val_loss: 4.2177 - val_acc: 0.8806\n",
            "Epoch 52/100\n",
            "100/100 - 63s - loss: 0.0542 - acc: 0.9949 - val_loss: 1.3312 - val_acc: 0.9534\n",
            "Epoch 53/100\n",
            "100/100 - 61s - loss: 0.1058 - acc: 0.9929 - val_loss: 0.3031 - val_acc: 0.9879\n",
            "Epoch 54/100\n",
            "100/100 - 65s - loss: 0.0684 - acc: 0.9970 - val_loss: 0.6932 - val_acc: 0.9737\n",
            "Epoch 55/100\n",
            "100/100 - 64s - loss: 0.0148 - acc: 0.9990 - val_loss: 0.7557 - val_acc: 0.9757\n",
            "Epoch 56/100\n",
            "100/100 - 64s - loss: 0.1682 - acc: 0.9929 - val_loss: 4.0345 - val_acc: 0.9049\n",
            "Epoch 57/100\n",
            "100/100 - 63s - loss: 0.0605 - acc: 0.9950 - val_loss: 0.4965 - val_acc: 0.9767\n",
            "Epoch 58/100\n",
            "100/100 - 63s - loss: 0.0663 - acc: 0.9944 - val_loss: 0.2665 - val_acc: 0.9919\n",
            "Epoch 59/100\n",
            "100/100 - 62s - loss: 0.0174 - acc: 0.9985 - val_loss: 1.6930 - val_acc: 0.9453\n",
            "Epoch 60/100\n",
            "100/100 - 63s - loss: 0.0576 - acc: 0.9945 - val_loss: 0.5074 - val_acc: 0.9787\n",
            "Epoch 61/100\n",
            "100/100 - 62s - loss: 0.0308 - acc: 0.9985 - val_loss: 1.8744 - val_acc: 0.9393\n",
            "Epoch 62/100\n",
            "100/100 - 62s - loss: 0.0743 - acc: 0.9955 - val_loss: 0.7499 - val_acc: 0.9777\n",
            "Epoch 63/100\n",
            "100/100 - 64s - loss: 0.0169 - acc: 0.9990 - val_loss: 0.8388 - val_acc: 0.9696\n",
            "Epoch 64/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 64s - loss: 0.0035 - acc: 0.9995 - val_loss: 7.6998 - val_acc: 0.7986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "d9ddbc97-5ad0-451d-c45b-4068390ba377"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfvdz5q8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38saYQxYxHrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}