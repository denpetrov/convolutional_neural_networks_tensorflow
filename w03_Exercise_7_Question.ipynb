{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w03: Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denpetrov/convolutional_neural_networks_tensorflow/blob/master/w03_Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83dfc212-3063-44c8-ce32-0b80f95f911c"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (300, 300, 3),  # Your Code Here\n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  # Your Code Here\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-06 20:11:51--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   176MB/s    in 0.5s    \n",
            "\n",
            "2019-07-06 20:11:51 (176 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0706 20:11:52.180853 139677911848832 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd777aec-8c6d-40dd-bf36-2634e10785da"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed10')  # Your Code Here\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output  # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 8, 8, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc') > 0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06ca13f4-95ab-4df2-95ea-ac6ffa9e8220"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)  # Your Code Here\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)  # Your Code Here\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)  # Your Code Here\n",
        "\n",
        "model = Model( pre_trained_model.input, x)  # Your Code Here\n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy',  # Your Code Here, \n",
        "              metrics = ['acc'])  # Your Code Here\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0706 20:12:02.872039 139677911848832 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 131072)       0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         134218752   flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 156,022,561\n",
            "Trainable params: 134,219,777\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0371c3e7-f3bb-40a9-cb45-696d4a325cff"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-06 20:12:05--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.124.128, 2607:f8b0:4001:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.124.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   171MB/s    in 0.8s    \n",
            "\n",
            "2019-07-06 20:12:06 (171 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-07-06 20:12:07--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-07-06 20:12:07 (255 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9c3ab41b-f5d6-4814-aafb-9af3cbe5eae1"
      },
      "source": [
        "train_dir = os.path.join('/tmp', 'training')\n",
        "validation_dir = os.path.join('/tmp', 'validation')\n",
        "\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses')  # Your Code Here\n",
        "train_humans_dir = os.path.join(train_dir, 'humans')  # Your Code Here\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses')  # Your Code Here\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')  # Your Code Here\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)  # Your Code Here\n",
        "train_humans_fnames = os.listdir(train_humans_dir)  # Your Code Here\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)  # Your Code Here\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)  # Your Code Here\n",
        "\n",
        "print(len(train_horses_fnames))  # Your Code Here\n",
        "print(len(train_humans_fnames))  # Your Code Here\n",
        "print(len(validation_horses_fnames))  # Your Code Here\n",
        "print(len(validation_humans_fnames))  # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ed7c1f25-dabd-4e79-ee47-4f76f78d05ed"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)  # Your Code Here\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)  # Your Code Here\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (300, 300))  # Your Code Here\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (300, 300))  # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34e88211-a6bf-4ac8-a402-7be45817f5c6"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()  # Your Code Here\n",
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data = validation_generator,\n",
        "                              steps_per_epoch = 100,\n",
        "                              epochs = 100,\n",
        "                              validation_steps = 50,\n",
        "                              verbose = 2,\n",
        "                              callbacks=[callbacks])  # Your Code Here"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 58s - loss: 1.3540 - acc: 0.9007 - val_loss: 0.0139 - val_acc: 0.9960\n",
            "Epoch 2/100\n",
            "100/100 - 51s - loss: 0.1761 - acc: 0.9691 - val_loss: 0.0107 - val_acc: 0.9960\n",
            "Epoch 3/100\n",
            "100/100 - 50s - loss: 0.1154 - acc: 0.9809 - val_loss: 0.0187 - val_acc: 0.9960\n",
            "Epoch 4/100\n",
            "100/100 - 49s - loss: 0.2529 - acc: 0.9714 - val_loss: 0.0056 - val_acc: 0.9960\n",
            "Epoch 5/100\n",
            "100/100 - 49s - loss: 0.1465 - acc: 0.9772 - val_loss: 0.0128 - val_acc: 0.9960\n",
            "Epoch 6/100\n",
            "100/100 - 49s - loss: 0.0917 - acc: 0.9853 - val_loss: 0.1355 - val_acc: 0.9798\n",
            "Epoch 7/100\n",
            "100/100 - 49s - loss: 0.0315 - acc: 0.9954 - val_loss: 1.2048e-07 - val_acc: 1.0000\n",
            "Epoch 8/100\n",
            "100/100 - 49s - loss: 0.2003 - acc: 0.9728 - val_loss: 3.9254e-09 - val_acc: 1.0000\n",
            "Epoch 9/100\n",
            "100/100 - 49s - loss: 0.0538 - acc: 0.9918 - val_loss: 1.5438e-10 - val_acc: 1.0000\n",
            "Epoch 10/100\n",
            "100/100 - 49s - loss: 0.0277 - acc: 0.9935 - val_loss: 8.8271e-09 - val_acc: 1.0000\n",
            "Epoch 11/100\n",
            "100/100 - 49s - loss: 0.0502 - acc: 0.9924 - val_loss: 3.4647e-06 - val_acc: 1.0000\n",
            "Epoch 12/100\n",
            "100/100 - 49s - loss: 0.1090 - acc: 0.9894 - val_loss: 3.4401e-09 - val_acc: 1.0000\n",
            "Epoch 13/100\n",
            "100/100 - 49s - loss: 0.0512 - acc: 0.9934 - val_loss: 1.1265e-08 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "100/100 - 49s - loss: 0.0441 - acc: 0.9929 - val_loss: 7.8709e-06 - val_acc: 1.0000\n",
            "Epoch 15/100\n",
            "100/100 - 51s - loss: 0.0256 - acc: 0.9970 - val_loss: 1.5931e-09 - val_acc: 1.0000\n",
            "Epoch 16/100\n",
            "100/100 - 50s - loss: 0.0567 - acc: 0.9929 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 17/100\n",
            "100/100 - 49s - loss: 0.0845 - acc: 0.9924 - val_loss: 0.0189 - val_acc: 0.9960\n",
            "Epoch 18/100\n",
            "100/100 - 49s - loss: 0.0915 - acc: 0.9904 - val_loss: 6.0618e-10 - val_acc: 1.0000\n",
            "Epoch 19/100\n",
            "100/100 - 49s - loss: 0.0704 - acc: 0.9889 - val_loss: 2.4939e-07 - val_acc: 1.0000\n",
            "Epoch 20/100\n",
            "100/100 - 48s - loss: 0.0408 - acc: 0.9934 - val_loss: 3.3666e-10 - val_acc: 1.0000\n",
            "Epoch 21/100\n",
            "100/100 - 49s - loss: 0.1059 - acc: 0.9914 - val_loss: 2.8740e-08 - val_acc: 1.0000\n",
            "Epoch 22/100\n",
            "100/100 - 48s - loss: 0.0323 - acc: 0.9959 - val_loss: 4.8464e-06 - val_acc: 1.0000\n",
            "Epoch 23/100\n",
            "100/100 - 49s - loss: 0.0187 - acc: 0.9959 - val_loss: 0.0056 - val_acc: 0.9960\n",
            "Epoch 24/100\n",
            "100/100 - 48s - loss: 0.0849 - acc: 0.9944 - val_loss: 0.0487 - val_acc: 0.9929\n",
            "Epoch 25/100\n",
            "100/100 - 49s - loss: 0.0363 - acc: 0.9970 - val_loss: 1.8594e-07 - val_acc: 1.0000\n",
            "Epoch 26/100\n",
            "100/100 - 48s - loss: 0.0252 - acc: 0.9970 - val_loss: 1.6868e-04 - val_acc: 1.0000\n",
            "Epoch 27/100\n",
            "100/100 - 48s - loss: 0.1388 - acc: 0.9889 - val_loss: 8.7660e-06 - val_acc: 1.0000\n",
            "Epoch 28/100\n",
            "100/100 - 51s - loss: 0.0679 - acc: 0.9965 - val_loss: 6.4182e-04 - val_acc: 1.0000\n",
            "Epoch 29/100\n",
            "100/100 - 49s - loss: 0.0515 - acc: 0.9939 - val_loss: 3.7750e-04 - val_acc: 1.0000\n",
            "Epoch 30/100\n",
            "100/100 - 49s - loss: 0.1049 - acc: 0.9919 - val_loss: 1.0081e-07 - val_acc: 1.0000\n",
            "Epoch 31/100\n",
            "100/100 - 49s - loss: 0.0392 - acc: 0.9970 - val_loss: 4.7632e-08 - val_acc: 1.0000\n",
            "Epoch 32/100\n",
            "100/100 - 49s - loss: 0.0543 - acc: 0.9944 - val_loss: 9.3421e-09 - val_acc: 1.0000\n",
            "Epoch 33/100\n",
            "100/100 - 49s - loss: 0.0300 - acc: 0.9955 - val_loss: 0.3750 - val_acc: 0.9676\n",
            "Epoch 34/100\n",
            "100/100 - 49s - loss: 0.0215 - acc: 0.9975 - val_loss: 0.0875 - val_acc: 0.9889\n",
            "Epoch 35/100\n",
            "100/100 - 49s - loss: 0.0064 - acc: 0.9990 - val_loss: 0.0110 - val_acc: 0.9960\n",
            "Epoch 36/100\n",
            "100/100 - 49s - loss: 0.0357 - acc: 0.9964 - val_loss: 0.0924 - val_acc: 0.9889\n",
            "Epoch 37/100\n",
            "100/100 - 49s - loss: 0.0153 - acc: 0.9985 - val_loss: 0.0694 - val_acc: 0.9879\n",
            "Epoch 38/100\n",
            "100/100 - 49s - loss: 0.0224 - acc: 0.9970 - val_loss: 0.1876 - val_acc: 0.9879\n",
            "Epoch 39/100\n",
            "100/100 - 49s - loss: 0.0449 - acc: 0.9959 - val_loss: 3.5660e-07 - val_acc: 1.0000\n",
            "Epoch 40/100\n",
            "100/100 - 49s - loss: 0.0498 - acc: 0.9954 - val_loss: 0.0919 - val_acc: 0.9879\n",
            "Epoch 41/100\n",
            "100/100 - 51s - loss: 0.0128 - acc: 0.9975 - val_loss: 0.0038 - val_acc: 0.9970\n",
            "Epoch 42/100\n",
            "100/100 - 49s - loss: 0.0320 - acc: 0.9965 - val_loss: 0.2228 - val_acc: 0.9879\n",
            "Epoch 43/100\n",
            "100/100 - 50s - loss: 0.0391 - acc: 0.9960 - val_loss: 0.5102 - val_acc: 0.9555\n",
            "Epoch 44/100\n",
            "100/100 - 49s - loss: 0.0437 - acc: 0.9954 - val_loss: 6.2350e-08 - val_acc: 1.0000\n",
            "Epoch 45/100\n",
            "100/100 - 49s - loss: 0.0331 - acc: 0.9960 - val_loss: 1.6060e-05 - val_acc: 1.0000\n",
            "Epoch 46/100\n",
            "100/100 - 49s - loss: 0.0118 - acc: 0.9980 - val_loss: 0.1349 - val_acc: 0.9919\n",
            "Epoch 47/100\n",
            "100/100 - 49s - loss: 0.0856 - acc: 0.9949 - val_loss: 8.6265e-05 - val_acc: 1.0000\n",
            "Epoch 48/100\n",
            "100/100 - 49s - loss: 0.0552 - acc: 0.9965 - val_loss: 0.0164 - val_acc: 0.9919\n",
            "Epoch 49/100\n",
            "100/100 - 49s - loss: 0.0203 - acc: 0.9954 - val_loss: 0.0199 - val_acc: 0.9919\n",
            "Epoch 50/100\n",
            "100/100 - 49s - loss: 0.0694 - acc: 0.9949 - val_loss: 0.4712 - val_acc: 0.9686\n",
            "Epoch 51/100\n",
            "100/100 - 49s - loss: 0.0396 - acc: 0.9959 - val_loss: 0.0116 - val_acc: 0.9919\n",
            "Epoch 52/100\n",
            "100/100 - 49s - loss: 0.0174 - acc: 0.9975 - val_loss: 0.2723 - val_acc: 0.9808\n",
            "Epoch 53/100\n",
            "100/100 - 49s - loss: 0.0677 - acc: 0.9959 - val_loss: 5.8253e-05 - val_acc: 1.0000\n",
            "Epoch 54/100\n",
            "100/100 - 51s - loss: 0.0577 - acc: 0.9950 - val_loss: 0.0612 - val_acc: 0.9960\n",
            "Epoch 55/100\n",
            "100/100 - 50s - loss: 0.0446 - acc: 0.9959 - val_loss: 0.0740 - val_acc: 0.9879\n",
            "Epoch 56/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 49s - loss: 2.4045e-05 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "33d7abbc-169a-48a8-a0b1-11ddb4b7dfba"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKvqKoigVCBV9RVGUCsT/A5Ib3sFFCLuwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38saYQxYxHrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}